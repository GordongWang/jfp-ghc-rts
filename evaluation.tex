\section{Execution model}

We begin our exploration of GHC's runtime system with a description
of the execution model of compiled Haskell code.

While the execution model of compiled code isn't in the domain of the
runtime system per se (it is the compiler's responsibility to generate
code that abides by the various conventions), various parts of the
execution model (e.g. heap representation, lazy evaluation) have an
important role to play in the design of components of the runtime system
(e.g. the garbage collector, concurrency).  In this section, we offer a
brief explanation of some of the most important aspects of the
\emph{Spineless Tagless G-machine} (STG), GHC's core execution model.

\subsection{G-machine}

How does a Haskell program run?  This is not a straightforward question
to answer, because a compiled Haskell program is not run directly: it is
transformed from Haskell into an intermediate representation called
Core, optimized, and transformed into another intermediate
representation (STG) before any code is generated.  Describing how
Haskell is desugared and what these optimizations are is out of scope
for this paper.  We have to discuss 

This intermediate representation is the STG, which has the benefits of
being both a functional language and having a clear operational reading.

What are the basic operations that STG code supports?  It 

\begin{itemize}
    \item Function application,
    \item Literals,
    \item Constructor application (saturated),
    \item Primitive operations (saturated),
    \item Evaluation of expressions and case-split of the result,
    \item Heap allocation (let) of closures (thunks or functions) and constructors,
    \item Let-no-escape,
\end{itemize}


\subsection{(Untitled)}

What does compiled Haskell code do?  Haskell is a high-level language,
and thus the executable code produced by a Haskell compiler bears little
resemblance to the code that was originally written.

Fortunately, GHC does have a \emph{purely
functional} intermediate language, which does have an operational
reading: this language is the \emph{Spineless Tagless
G-machine}.~\cite{PeytonJones1992}.

STG is 

\begin{itemize}
    \item Function application: tail call (direct jump)
    \item Let expression: heap allocation
    \item Case expression: evaluation of a thunk
    \item Constructor application: return to continuation
\end{itemize}



The fact that all function applications are tail calls is perhaps what
causes the largest divergence between the runtime execution of Haskell
and other block-structured languages.  In C, when a function is entered
a stack frame (e.g. continuation) is always pushed onto the stack; in
Haskell, we may push zero, one, or more frames on the stack before
jumping to the function destination.

While there are many details to STG, for which an interested reader
should consult \cite{PeytonJones1992} and \cite{Marlow2006}, a brief
overview of the STG will be useful for understanding some of the things
the runtime system needs to support.  STG is a simple lambda calculus,
for which the following common operations are given an operational
reading:

\subsection{Spineless Tagless G-machine}

The Spineless Tagless G-machine (STG) is 

\subsection{Heap representation}

All data on the heap is boxed, represented with a \emph{header}, which
indicates what kind of object the data is, and the \emph{payload}, which
contains the actual data for an object.  The header points to an
\emph{info table}, which provides more information about whether or not
the object is a thunk, a data constructor or a function, and describes
the layout of the payload in more detail (e.g. what fields are
pointers.) \Red{Figure}

\subsection{Spineless: Stack}

\Red{Maybe defer this later?}

\Red{Haskell code executes utilizing a \emph{eval/apply} model}



\subsection{Tagless: Lazy evaluation}

Unusually, the info table also contains \emph{code} for the object: any
object can be ``entered'' (by jumping to the code in the infotable) in
order to evaluate it.  This is perhaps the most important design
decision in STG: it prescribes a uniform data representation for both
fully evaluated data values (constructors and functions) and unevaluated
thunks---referred to collectively as \emph{closures}.  In the original
design of the STG, all code wanting to access a field in a data
structure first entered the closure and upon return would receive the
values of the data structure (a \emph{vectored return}).  The lack of
any check whether or not a thunk was evaluated or not (an obvious
alternative implementation strategy) is behind the ``tagless`` in STG's
name.

\SM{We don't do vectored returns, since GHC 4.0. Also
  return-in-registers, which you might also find menioned in the
  original STG paper, was removed in favour of unboxed tuples.}

\SM{Tagless is a bit debatable these days.  We have tags in pointers
  (pointer tagging).  Also the code pointer for a function closure is
  the entry code for the function (not the ``eval'' code).}

The fact that objects are always entered is an extremely helpful layer
of indirection which is used for a variety of purposes by the runtime.
For example, when a thunk finishes evaluation, we need to write back the
true value to the old memory location so the computation is not
repeated.  If the new value is larger than the thunk, it must be placed
in new heap memory and the old thunk replaced with an \emph{indirection}
pointer pointing to the new value.  An indirection object, then, simply
jumps to the code of the indirectee!  This flexibility is useful for a
number of other exceptional conditions, especially in the case of
concurrency.

Unfortunately, code compiled this way performs a lot of indirect jumps,
and modern branch prediction units on processors typically perform very
poorly under such control flow.  This might suggest that this data
representation is quite expensive and of little interest to implementors
of non-lazy languages.  Fortunately, modern GHC implements a
\emph{dynamic pointer tagging} scheme~\XXX{} which, in many cases,
eliminates the need to perform an indirect jump.  This scheme works by
using the lower order bits (two bits in a 32-bit machine, and three bits
in a 64-bit machine) in order to encode whether or not pointer is
already evaluated, and if it is, what the tag of the constructor is.
When the tag bit is absent, user code will enter the closure, as before.

We think that this representation is well worth considering even for
non-lazy-by-default languages.  In the case of data types with multiple
constructors, pointer tagging enables us to support efficient case
analysis of user-defined types \emph{without a memory
dereference}---only the tag bit must be consulted.  And, to reiterate,
the added flexibility the indirect jumps will greatly aid us later in
other components of the runtime system.

\Red{Maybe explain in more detail}

\subsection{Black holes} \label{sec:blackhole}

One particular type of closure worth some attention is the \emph{black
hole}.  The semantics of a black hole are relatively simple: a black
hole represents a thunk that is currently being evaluated.  A thunk
can be \emph{claimed} by overwriting it with a black hole. The entry
code for a black hole should arrange for the thread to receive the value
of the thunk after it is evaluated, some way or another.

Black holes were originally proposed as a solution for a space leak that
occurs when tail calls are being made in the STG.~\cite{Jones2008} The
problem is relatively simple: suppose that you are evaluating the thunk \verb|last [1..10000]|,
where \verb|last| is a tail recursive function:

\begin{verbatim}
last []     = error "empty list"
last (x:[]) = x
last (x:xs) = last xs
\end{verbatim}

Because \verb|[1..10000]| is constructed lazily, you might expect
evaluating this thunk to take constant space, since the front of the
list is never retained.  However, there is a problem: the front of the
list is retained by the thunk itself, \verb|last [1..10000]|.  The thunk
will eventually get overwritten by the result of the computation, but
only at the \emph{end} of the computation, by which point the entirety
of \verb|[1..10000]| is resident in memory.  To solve this problem, when
\verb|last [1..10000]| is evaluated, we can \emph{eagerly} overwrite it
with a \verb|BLACKHOLE|; now the thunk no longer retains the list.  As
an optimization, we can \emph{lazily} blackhole by waiting until the
thread becomes descheduled, e.g. for a garbage collection.

The simplicity of black holes belies their utility in a variety of contexts.
In particular:

\begin{itemize}
\item Black holes allow us to detect some infinite loops: if a thread attempts
    to evaluate a black hole which it previously claimed, that is an infinite loop!
\item In a multiprocessor setting, black holes allow us to avoid duplicating work when multiple
    threads attempt to evaluate the same object.\footnote{It is worth noting that for this use-case, we have to \emph{eagerly} blackhole thunks.}  Instead, a thread blocks on the owner
    of a black hole, waiting for it to finish processing.  This is described in more
    detail in Section~\ref{sec:sync}.
\end{itemize}

\subsection{Notes}

\Red{More stuff}

While the original paper about the Spineless Tagless
G-machine~\cite{PeytonJones1992} remains the best source for an
in-detail explanation about STG, many details have changed over the two
decades it has been last published.  If one had to sum up its modern
implementation in GHC, one might call it the ``Usually-Spineless
Mostly-Tagged G-machine.''  Briefly, the important changes are as
follows:

\begin{itemize}
    \item STG is no longer compiled into C, instead, it is
        compiled into a more low-level language C--~\cite{Jones1999}, allowing
        GHC to change details such as calling conventions and utilize
        more low level functionality (e.g. tail calls, explicit stack
        layout, computing targets of jumps and implementing exceptions).
    \item The stipulation that closures have a uniform representation
        has been relaxed.  The most important change is how functions
        are represented: while the paper originally proposed a push/enter
        model, GHC now uses an eval/apply model~\cite{Marlow2006}, in
        which the code pointer of function info tables points to the code
        for the function itself, and not code for reading arguments off of
        the stack.  This also means that the stack representation is
        different: there is now only a single stack for continuations and
        update frames (alongside the second C stack for register spills).
    \item Furthermore, pointers are dynamically tagged with information
        that may allow code to avoid jumping into a closure in order to
        ensure that it is evaluated---STG is not
        tagless!~\cite{Marlow2007}  The original dynamic tagging paper
        suggests that these tags could be erased for only a performance
        hit, but in fact, in some places, they are required.  This also
        means that vectored-returns have gone the way of the dinosaur.
    \item The spineless in STG's name refers to the fact that GHC stores
        the intermediate state of evaluating a thunk on the stack,
        rather than on the ``spine'' of the thunk itself.  Under some
        circumstances, such as in the case of an interrupt, it is
        profitable to write out this state back to the thunk, so that
        this work can be resumed later.~\cite{Reid1999} \Red{Maybe this is gratuitous}
\end{itemize}
