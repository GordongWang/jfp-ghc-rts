\section{Execution model}

We begin our exploration of GHC's runtime system with a description
of the execution model of compiled Haskell code.

While the execution model of compiled code isn't in the domain of the
runtime system per se (it is the compiler's responsibility to generate
code that abides by the various conventions), various parts of the
execution model (e.g. heap representation, lazy evaluation) have an
important role to play in the design of components of the runtime system
(e.g. the garbage collector, concurrency).  In this section, we offer a
brief explanation of some of the most important aspects of the
\emph{Spineless Tagless G-machine} (STG), GHC's core execution model.

\subsection{STG}

How does a Haskell program run?  This is not a straightforward question
to answer, because a compiled Haskell program is not run directly: it is
desugared into an intermediate representation called Core, optimized,
and transformed into another intermediate representation (STG) before
any code is generated.  Describing how Haskell is desugared and
optimized is out of scope for this paper.  Thus, we cannot directly talk
about how Haskell runs, rather, we can only talk about a abstract
machine language which resembles Haskell, but is designed to be easy to
generate code for.

This abstract machine is the \emph{Spineless Tagless G-machine}, and it
is a functional language.  Like Haskell, it has function application,
literals, constructors, primitive operations, let-bindings amd
case-expressions.  However, it imposes a few simplifying restrictions
(for example, there are no lambda literals: they must be top-level or
let-bound before use).  These restrictions allow us to make four
important equivalences between language and operation:

\begin{itemize}
    \item \emph{Let expressions} are \emph{heap allocation},
    \item \emph{Function application} is a \emph{tail call},
    \item \emph{Case expressions} are \emph{evaluation}, and
    \item \emph{Constructor application} is a \emph{return to continuation}.
\end{itemize}

We now consider each of these constructs in turn.

\subsection{Let-binding and heap allocation}

Heap allocation is of central importance to Haskell programs: most data
values, function values, and thunks are all allocated on the heap.  These objects are
all referred to collectively as \emph{closures}.  All of these heap
objects are represented uniformly, with a \emph{header}, which indicates
what kind of object the data is, and the \emph{payload}, which contains
the actual data for an object (e.g. free variables for function values
and thunks, or fields for data values).  The header points to an
\emph{info table}, which provides more information about what kind of
object the closure is, what code is associated with the object and what
the layout of the payload is (e.g. what fields are pointers.)
\Red{Figure}

An important optimization is the \emph{let-no-escape} binding.  True
to its name, let-no-escape indicates that the contents of the variable
do not escape from the scope it was allocated in.  Because 

\subsection{Function application and tail calls}

%   \begin{itemize}
%       \item There are no literal lambdas; instead, a lambda must either be lifted to the top-level of the program or be allocated via a let-binding.  Requiring this makes \emph{heap allocation} explicit, because a heap allocation can only occur when a let-binding occurs.
%       \item Constructor application and primitive operations must be \emph{saturated}, that is, they must be provided with all of the arguments they expect.  Ordinarily, these operations are curried, so partially applied forms are OK; in STG, they are wrapped in lambdas.
%       \item Evaluation of expressions and case-split of the result,
%       \item Heap allocation (let) of closures (thunks or functions) and constructors,
%       \item Let-no-escape,
%   \end{itemize}


\subsection{(Untitled)}

The fact that all function applications are tail calls is perhaps what
causes the largest divergence between the runtime execution of Haskell
and other block-structured languages.  In C, when a function is entered
a stack frame (e.g. continuation) is always pushed onto the stack; in
Haskell, we may push zero, one, or more frames on the stack before
jumping to the function destination.

\subsection{Heap representation}

\subsection{Spineless: Stack}

\Red{Maybe defer this later?}

\Red{Haskell code executes utilizing a \emph{eval/apply} model}



\subsection{Tagless: Lazy evaluation}

Unusually, the info table also contains \emph{code} for the object: any
object can be ``entered'' (by jumping to the code in the infotable) in
order to evaluate it.  This is perhaps the most important design
decision in STG: it prescribes a uniform data representation for both
fully evaluated data values (constructors and functions) and unevaluated
thunks---referred to collectively as \emph{closures}.  In the original
design of the STG, all code wanting to access a field in a data
structure first entered the closure and upon return would receive the
values of the data structure (a \emph{vectored return}).  The lack of
any check whether or not a thunk was evaluated or not (an obvious
alternative implementation strategy) is behind the ``tagless`` in STG's
name.

\SM{We don't do vectored returns, since GHC 4.0. Also
  return-in-registers, which you might also find menioned in the
  original STG paper, was removed in favour of unboxed tuples.}

\SM{Tagless is a bit debatable these days.  We have tags in pointers
  (pointer tagging).  Also the code pointer for a function closure is
  the entry code for the function (not the ``eval'' code).}

The fact that objects are always entered is an extremely helpful layer
of indirection which is used for a variety of purposes by the runtime.
For example, when a thunk finishes evaluation, we need to write back the
true value to the old memory location so the computation is not
repeated.  If the new value is larger than the thunk, it must be placed
in new heap memory and the old thunk replaced with an \emph{indirection}
pointer pointing to the new value.  An indirection object, then, simply
jumps to the code of the indirectee!  This flexibility is useful for a
number of other exceptional conditions, especially in the case of
concurrency.

Unfortunately, code compiled this way performs a lot of indirect jumps,
and modern branch prediction units on processors typically perform very
poorly under such control flow.  This might suggest that this data
representation is quite expensive and of little interest to implementors
of non-lazy languages.  Fortunately, modern GHC implements a
\emph{dynamic pointer tagging} scheme~\XXX{} which, in many cases,
eliminates the need to perform an indirect jump.  This scheme works by
using the lower order bits (two bits in a 32-bit machine, and three bits
in a 64-bit machine) in order to encode whether or not pointer is
already evaluated, and if it is, what the tag of the constructor is.
When the tag bit is absent, user code will enter the closure, as before.

We think that this representation is well worth considering even for
non-lazy-by-default languages.  In the case of data types with multiple
constructors, pointer tagging enables us to support efficient case
analysis of user-defined types \emph{without a memory
dereference}---only the tag bit must be consulted.  And, to reiterate,
the added flexibility the indirect jumps will greatly aid us later in
other components of the runtime system.

\Red{Maybe explain in more detail}

\subsection{Black holes} \label{sec:blackhole}

One particular type of closure worth some attention is the \emph{black
hole}.  The semantics of a black hole are relatively simple: a black
hole represents a thunk that is currently being evaluated.  A thunk
can be \emph{claimed} by overwriting it with a black hole. The entry
code for a black hole should arrange for the thread to receive the value
of the thunk after it is evaluated, some way or another.

Black holes were originally proposed as a solution for a space leak that
occurs when tail calls are being made in the STG.~\cite{Jones2008} The
problem is relatively simple: suppose that you are evaluating the thunk \verb|last [1..10000]|,
where \verb|last| is a tail recursive function:

\begin{verbatim}
last []     = error "empty list"
last (x:[]) = x
last (x:xs) = last xs
\end{verbatim}

Because \verb|[1..10000]| is constructed lazily, you might expect
evaluating this thunk to take constant space, since the front of the
list is never retained.  However, there is a problem: the front of the
list is retained by the thunk itself, \verb|last [1..10000]|.  The thunk
will eventually get overwritten by the result of the computation, but
only at the \emph{end} of the computation, by which point the entirety
of \verb|[1..10000]| is resident in memory.  To solve this problem, when
\verb|last [1..10000]| is evaluated, we can \emph{eagerly} overwrite it
with a \verb|BLACKHOLE|; now the thunk no longer retains the list.  As
an optimization, we can \emph{lazily} blackhole by waiting until the
thread becomes descheduled, e.g. for a garbage collection.

The simplicity of black holes belies their utility in a variety of contexts.
In particular:

\begin{itemize}
\item Black holes allow us to detect some infinite loops: if a thread attempts
    to evaluate a black hole which it previously claimed, that is an infinite loop!
\item In a multiprocessor setting, black holes allow us to avoid duplicating work when multiple
    threads attempt to evaluate the same object.\footnote{It is worth noting that for this use-case, we have to \emph{eagerly} blackhole thunks.}  Instead, a thread blocks on the owner
    of a black hole, waiting for it to finish processing.  This is described in more
    detail in Section~\ref{sec:sync}.
\end{itemize}

\subsection{Notes}

\Red{More stuff}

While the original paper about the Spineless Tagless
G-machine~\cite{PeytonJones1992} remains the best source for an
in-detail explanation about STG, many details have changed over the two
decades it has been last published.  If one had to sum up its modern
implementation in GHC, one might call it the ``Usually-Spineless
Mostly-Tagged G-machine.''  Briefly, the important changes are as
follows:

\begin{itemize}
    \item STG is no longer compiled into C, instead, it is
        compiled into a more low-level language C--~\cite{Jones1999}, allowing
        GHC to change details such as calling conventions and utilize
        more low level functionality (e.g. tail calls, explicit stack
        layout, computing targets of jumps and implementing exceptions).
    \item The stipulation that closures have a uniform representation
        has been relaxed.  The most important change is how functions
        are represented: while the paper originally proposed a push/enter
        model, GHC now uses an eval/apply model~\cite{Marlow2006}, in
        which the code pointer of function info tables points to the code
        for the function itself, and not code for reading arguments off of
        the stack.  This also means that the stack representation is
        different: there is now only a single stack for continuations and
        update frames (alongside the second C stack for register spills).
    \item Furthermore, pointers are dynamically tagged with information
        that may allow code to avoid jumping into a closure in order to
        ensure that it is evaluated---STG is not
        tagless!~\cite{Marlow2007}  The original dynamic tagging paper
        suggests that these tags could be erased for only a performance
        hit, but in fact, in some places, they are required.  This also
        means that vectored-returns have gone the way of the dinosaur.
    \item The spineless in STG's name refers to the fact that GHC stores
        the intermediate state of evaluating a thunk on the stack,
        rather than on the ``spine'' of the thunk itself.  Under some
        circumstances, such as in the case of an interrupt, it is
        profitable to write out this state back to the thunk, so that
        this work can be resumed later.~\cite{Reid1999} \Red{Maybe this is gratuitous}
\end{itemize}
